{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "161a0f96",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "There is a GD expression that we have all seen. And we know how backprop works with the forward, backward, and update rule. We also know how to imagine the landscape of loss where each weight is plotted on an axis with loss on the other axis and our goal is to get to the lowest loss using that weight. \n",
    "\n",
    "As we trudge along this landscape of loss, we realize that we are doing the most fundamental part of deep learning. If we think of llms as a giant mathematical expression, then the main objective of training is to tune the constants in that expression (weights). To move the weights such that the resulting expression is close enough to the data manifold used during training is the main objective of training. And in that sense, deep learning is essentially an optimization problem. \n",
    "\n",
    "And then if moving across this landscape and finding that elusive global minima in this fractured landscape is the goal, we start seeing that the key starts becoming exactly *how* we move through it. \n",
    "\n",
    "In this notebook, that is what we will cover. And for me, that is also the *hook* for optimizers. Because while it can get deeply mathematical and the explanations can get quite abstract, the truth is that at the end of the day, all we're doing is writing an algorithm to walk down a hill."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f3e634",
   "metadata": {},
   "source": [
    "# Weight Update Formula\n",
    "\n",
    "Let's review the most basic/fundamental weight update formula as done through vanilla SGD. This disucssion is a bit off topic, but I went through this rabbit hole for a while so just noting it down here. Also, only writing down the high level points, deeper analysis will lead to the question of what it means to stabilize the weight update equation, and by corollary, training itself - which is a larger question and won't be analyzed here. Idea here is just to think of the intuition. \n",
    "\n",
    "Here is the equation:\n",
    "\n",
    "W_new = W_old - lr * L'(W_old)\n",
    "\n",
    "There is something about this equation that feels a bit wrong. \n",
    "\n",
    "For example, at the most funadmental level, are the units in all the terms the same? Thinking from a physics perspective, if we strictly assign physical units, W_old is a position (e.g., \"meters\") and the gradient grad(f'(W_old)) is a slope (\"energy per meter\"). Subtracting a slope from a position is just physically impossible~ This reveals that the gradient is merely a directional signal (force) indicating urgency, not a spatial displacement. The equation requires a conversion factor to translate \"steepness of the hill\" into \"distance to step.\"\n",
    "\n",
    "Perhaps the resolution to this paradox lies in the Taylor Series expansion of the loss function. The \"perfect\" update rule, which accounts for the landscape's geometry, is:\n",
    "\n",
    "W_new = W_old - lr * ( L'(W_old) / L''(W_old) )\n",
    "\n",
    "Here, the numerator (gradient, $L'$) provides the push, while the denominator (curvature/Hessian, $L''$) provides the braking mechanism. Dimensionally, it can be argued that this balances because: the units of curvature (${energy}/{{meters}^2}$) divide the units of gradient (${energy}/{{meters}}$), canceling out the \"energy\" and leaving purely \"meters.\" So it can be argued that this confirms that a valid update step requires two distinct derivatives: one to determine direction ($L'$) and one to determine scale ($L''$).\n",
    "\n",
    "Of course, calculating the Hessian ($L''$) is computationally intractable for millions of parameters. Therefore, the learning rate $lr$ acts as a constant scalar proxy for the inverse curvature (1/{L''}$). When we set a learning rate, we are effectively guessing the geometry of the error surface. A high $lr$ assumes low curvature (a wide, flat valley where big steps are safe), while a low $lr$ assumes high curvature (a sharp, narrow ravine where precision is required). Thus, $lr$, in addition to being a speed setting, is also a unit-restoring term that bridges the gap between the \"force\" of the gradient and the \"displacement\" of the weight update."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104ca402",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
